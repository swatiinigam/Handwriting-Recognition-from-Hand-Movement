{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e08f5d2-9895-403b-aa03-2c95401e302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp310-cp310-win_amd64.whl (51.0 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting jax\n",
      "  Using cached jax-0.5.2-py3-none-any.whl (2.4 MB)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Collecting protobuf<5,>=4.25.3\n",
      "  Using cached protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Collecting sounddevice>=0.4.4\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from mediapipe) (25.1.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "Collecting jaxlib\n",
      "  Using cached jaxlib-0.5.1-cp310-cp310-win_amd64.whl (65.2 MB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Collecting ml_dtypes>=0.4.0\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Collecting opt_einsum\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting scipy>=1.11.1\n",
      "  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.56.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\swati\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Installing collected packages: sentencepiece, flatbuffers, pyparsing, protobuf, pillow, opt_einsum, numpy, kiwisolver, fonttools, cycler, absl-py, sounddevice, scipy, opencv-python, opencv-contrib-python, ml_dtypes, contourpy, matplotlib, jaxlib, jax, mediapipe\n",
      "Successfully installed absl-py-2.1.0 contourpy-1.3.1 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.56.0 jax-0.5.2 jaxlib-0.5.1 kiwisolver-1.4.8 matplotlib-3.10.1 mediapipe-0.10.21 ml_dtypes-0.5.1 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86 opt_einsum-3.4.0 pillow-11.1.0 protobuf-4.25.6 pyparsing-3.2.1 scipy-1.15.2 sentencepiece-0.2.0 sounddevice-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Swati\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'C:\\Users\\Swati\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e6792-6fab-41c9-a578-6abb2da07ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hand Detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip coordinates\n",
    "            index_finger_tip = hand_landmarks.landmark[8]  # Index finger tip (Landmark 8)\n",
    "            h, w, c = frame.shape\n",
    "            x, y = int(index_finger_tip.x * w), int(index_finger_tip.y * h)\n",
    "\n",
    "            # Draw only when the previous position exists (i.e., finger is moving)\n",
    "            if prev_x is not None and prev_y is not None:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (x, y), (0, 255, 0), 5)\n",
    "\n",
    "            prev_x, prev_y = x, y  # Update previous position\n",
    "\n",
    "    # Combine the original frame with the drawn strokes\n",
    "    frame = cv2.addWeighted(frame, 0.5, canvas, 0.5, 0)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca24e37-ddd2-43ba-ac17-fb3c6f166b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hand Detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip coordinates\n",
    "            index_finger_tip = hand_landmarks.landmark[8]  # Index finger tip (Landmark 8)\n",
    "            h, w, c = frame.shape\n",
    "            x, y = int(index_finger_tip.x * w), int(index_finger_tip.y * h)\n",
    "\n",
    "            # Draw only when the previous position exists (i.e., finger is moving)\n",
    "            if prev_x is not None and prev_y is not None:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (x, y), (255, 255, 255), 5)  # White strokes\n",
    "\n",
    "            prev_x, prev_y = x, y  # Update previous position\n",
    "\n",
    "    # Merge drawing canvas with the webcam feed\n",
    "    frame = cv2.addWeighted(frame, 0.3, canvas, 0.7, 0)  # Increase stroke visibility\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas, 's' to save\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"handwriting_output.png\", canvas)\n",
    "        print(\"Handwriting saved as 'handwriting_output.png'\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd45bd9-d19d-47c9-9480-bd6f12a7c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hand Detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip coordinates\n",
    "            index_finger_tip = hand_landmarks.landmark[8]  # Index finger tip (Landmark 8)\n",
    "            h, w, c = frame.shape\n",
    "            x, y = int(index_finger_tip.x * w), int(index_finger_tip.y * h)\n",
    "\n",
    "            # Draw only when the previous position exists (i.e., finger is moving)\n",
    "            if prev_x is not None and prev_y is not None:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (x, y), (255, 255, 255), 5)  # White strokes\n",
    "\n",
    "            prev_x, prev_y = x, y  # Update previous position\n",
    "\n",
    "    # Merge drawing canvas with the webcam feed\n",
    "    frame_with_drawing = cv2.addWeighted(frame, 0.3, canvas, 0.7, 0)  # Increase stroke visibility\n",
    "\n",
    "    # Display the webcam feed with drawing\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame_with_drawing)\n",
    "\n",
    "    # Show only the handwriting separately\n",
    "    cv2.imshow(\"Handwritten Output\", canvas)\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas, 's' to save\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"handwriting_output.png\", canvas)\n",
    "        print(\"Handwriting saved as 'handwriting_output.png'\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831cf89c-a4e2-4c94-8c70-ea1812ba6172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handwriting saved as 'handwriting_output.png'\n",
      "Handwriting saved as 'handwriting_output.png'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hand Detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip coordinates\n",
    "            index_finger_tip = hand_landmarks.landmark[8]  # Index finger tip (Landmark 8)\n",
    "            h, w, c = frame.shape\n",
    "            x, y = int(index_finger_tip.x * w), int(index_finger_tip.y * h)\n",
    "\n",
    "            # Draw only when the previous position exists (i.e., finger is moving)\n",
    "            if prev_x is not None and prev_y is not None:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (x, y), (255, 255, 255), 5)  # White strokes\n",
    "\n",
    "            prev_x, prev_y = x, y  # Update previous position\n",
    "\n",
    "    # Merge drawing canvas with the webcam feed\n",
    "    frame_with_drawing = cv2.addWeighted(frame, 0.3, canvas, 0.7, 0)  # Increase stroke visibility\n",
    "\n",
    "    # Display the webcam feed with drawing\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame_with_drawing)\n",
    "    cv2.moveWindow(\"Handwriting Recognition\", 100, 100)  # Move webcam window to top-left\n",
    "\n",
    "    # Show only the handwriting separately\n",
    "    cv2.imshow(\"Handwritten Output\", canvas)\n",
    "    cv2.moveWindow(\"Handwritten Output\", 800, 100)  # Move handwriting window to right\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas, 's' to save\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"handwriting_output.png\", canvas)\n",
    "        print(\"Handwriting saved as 'handwriting_output.png'\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd4ba57-5c77-4c4f-83ae-83c96af78f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handwriting saved as 'handwriting_output.png'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Hand Detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "drawing = False  # Flag to check if writing should start\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip (8) and thumb tip (4) coordinates\n",
    "            h, w, c = frame.shape\n",
    "            index_x, index_y = int(hand_landmarks.landmark[8].x * w), int(hand_landmarks.landmark[8].y * h)\n",
    "            thumb_x, thumb_y = int(hand_landmarks.landmark[4].x * w), int(hand_landmarks.landmark[4].y * h)\n",
    "\n",
    "            # Calculate distance between index finger and thumb\n",
    "            distance = math.hypot(index_x - thumb_x, index_y - thumb_y)\n",
    "\n",
    "            # Only draw when fingers are pinched together (distance < 30)\n",
    "            if distance < 30:\n",
    "                drawing = True  # Start writing\n",
    "            else:\n",
    "                drawing = False  # Stop writing\n",
    "\n",
    "            # Draw only when the previous position exists and drawing mode is ON\n",
    "            if prev_x is not None and prev_y is not None and drawing:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (index_x, index_y), (255, 255, 255), 5)  # White strokes\n",
    "\n",
    "            prev_x, prev_y = index_x, index_y  # Update previous position\n",
    "\n",
    "    # Merge drawing canvas with the webcam feed\n",
    "    frame_with_drawing = cv2.addWeighted(frame, 0.3, canvas, 0.7, 0)  # Increase stroke visibility\n",
    "\n",
    "    # Display the webcam feed with drawing\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame_with_drawing)\n",
    "    cv2.moveWindow(\"Handwriting Recognition\", 100, 100)  # Move webcam window to top-left\n",
    "\n",
    "    # Show only the handwriting separately\n",
    "    cv2.imshow(\"Handwritten Output\", canvas)\n",
    "    cv2.moveWindow(\"Handwritten Output\", 800, 100)  # Move handwriting window to right\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas, 's' to save\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"handwriting_output.png\", canvas)\n",
    "        print(\"Handwriting saved as 'handwriting_output.png'\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac892c-8020-42f9-b608-a6f743f2d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a blank canvas to draw\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# To store previous finger position\n",
    "prev_x, prev_y = None, None\n",
    "drawing = False  # Flag to check if writing should start\n",
    "\n",
    "# Smooth movement variables\n",
    "smooth_x, smooth_y = None, None\n",
    "alpha = 0.3  # Smoothing factor (higher means smoother but slower response)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip (8) and thumb tip (4) coordinates\n",
    "            h, w, c = frame.shape\n",
    "            index_x, index_y = int(hand_landmarks.landmark[8].x * w), int(hand_landmarks.landmark[8].y * h)\n",
    "            thumb_x, thumb_y = int(hand_landmarks.landmark[4].x * w), int(hand_landmarks.landmark[4].y * h)\n",
    "\n",
    "            # Calculate distance between index finger and thumb\n",
    "            distance = math.hypot(index_x - thumb_x, index_y - thumb_y)\n",
    "\n",
    "            # Only draw when fingers are pinched together (distance < 30)\n",
    "            if distance < 30:\n",
    "                drawing = True  # Start writing\n",
    "            else:\n",
    "                drawing = False  # Stop writing\n",
    "                prev_x, prev_y = None, None  # Reset position to avoid jumps\n",
    "\n",
    "            # Apply smoothing to finger movement\n",
    "            if smooth_x is None or smooth_y is None:\n",
    "                smooth_x, smooth_y = index_x, index_y\n",
    "            else:\n",
    "                smooth_x = int(alpha * index_x + (1 - alpha) * smooth_x)\n",
    "                smooth_y = int(alpha * index_y + (1 - alpha) * smooth_y)\n",
    "\n",
    "            # Draw only when the previous position exists and drawing mode is ON\n",
    "            if prev_x is not None and prev_y is not None and drawing:\n",
    "                cv2.line(canvas, (prev_x, prev_y), (smooth_x, smooth_y), (255, 255, 255), 5)  # White strokes\n",
    "\n",
    "            prev_x, prev_y = smooth_x, smooth_y  # Update previous position\n",
    "\n",
    "    # Merge drawing canvas with the webcam feed\n",
    "    frame_with_drawing = cv2.addWeighted(frame, 0.3, canvas, 0.7, 0)  # Increase stroke visibility\n",
    "\n",
    "    # Display the webcam feed with drawing\n",
    "    cv2.imshow(\"Handwriting Recognition\", frame_with_drawing)\n",
    "    cv2.moveWindow(\"Handwriting Recognition\", 100, 100)  # Move webcam window to top-left\n",
    "\n",
    "    # Show only the handwriting separately\n",
    "    cv2.imshow(\"Handwritten Output\", canvas)\n",
    "    cv2.moveWindow(\"Handwritten Output\", 800, 100)  # Move handwriting window to right\n",
    "\n",
    "    # Press 'q' to exit, 'c' to clear the canvas, 's' to save\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        canvas[:] = 0  # Clear the canvas\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"handwriting_output.png\", canvas)\n",
    "        print(\"Handwriting saved as 'handwriting_output.png'\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf5547-162c-4625-898e-4aada82ad0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
